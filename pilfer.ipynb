{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import os\n",
    "import time\n",
    "from file_organizers import read_links_from_file, iterate_on_lib, create_directory\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "source_file = os.path.join(\n",
    "    \"file_lists\", \"done - Seminar - 2018 LA - Gogyo No Kata and Hanbo.txt\"\n",
    ")\n",
    "dist_root = \"download\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse site string. Returns video name and url\n",
    "def parse_site_string(site: str):\n",
    "    siteParts = site.split(\" - \", 1)\n",
    "    url = siteParts[0]\n",
    "\n",
    "    if len(siteParts) > 1:\n",
    "        video_name = siteParts[1]\n",
    "\n",
    "        # Clean out any special characters which don't fit in a windows file name\n",
    "        video_name = (\n",
    "            video_name.replace(\"/\", \"、\")\n",
    "            .replace(\"\\\\\", \"、\")\n",
    "            .replace(\":\", \" -\")\n",
    "            .replace(\"@\", \"_at_\")\n",
    "            .replace(\"#\", \"_\")\n",
    "            .replace(\"?\", \"_\")\n",
    "            .replace(\"*\", \"_\")\n",
    "            .replace(\">\", \"_\")\n",
    "            .replace(\"<\", \"_\")\n",
    "            .replace(\"|\", \"、\")\n",
    "        )\n",
    "    else:\n",
    "        video_name = \"\"\n",
    "\n",
    "    return [video_name, url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "\n",
    "# Find and return path to the highest-resolution file\n",
    "def get_media_playlist_file_path(video_name: str, url: str) -> tuple[int, int, str]:\n",
    "    \"\"\"NOTE: We do not sort out files which partially match the video_name\n",
    "    as we always want to know if a higher-resolution file has become available\"\"\"\n",
    "\n",
    "    # Check if we have the correct file ending\n",
    "    if not url.split(\"?\")[0].endswith(\".m3u8\"):\n",
    "        raise Exception(\n",
    "            f\"File {video_name}'s url does not end in m3u8 and so does not promise to be a utf-8 encoded m3u file. \\nAt url {url}\"\n",
    "        )\n",
    "\n",
    "    with requests.get(url, stream=True) as file:\n",
    "        # Help the response headers a bit with figuring out the file's encoding\n",
    "        file.encoding = \"utf-8\"\n",
    "\n",
    "        # Check first line indicates valid m3u\n",
    "        if not file.content.startswith(b\"#EXTM3U\"):\n",
    "            raise Exception(\n",
    "                f\"File {video_name} is not formatted as m3u file. First line is not '#EXTM3U' \\n At url {url}\"\n",
    "            )\n",
    "\n",
    "        # Store biggest resolution found in master playlist file\n",
    "        biggest_res: tuple[int, int] = (0, 0)\n",
    "        best_url: str = url\n",
    "\n",
    "        # Find all file variants\n",
    "        for match in re.finditer(\n",
    "            \"RESOLUTION=(\\\\d{3,5})x(\\\\d{3,5}).*\\\\n(.*)\",\n",
    "            file.content.decode(),\n",
    "            re.MULTILINE,\n",
    "        ):\n",
    "            width = int(match.group(1))\n",
    "            height = int(match.group(2))\n",
    "\n",
    "            # Store biggest resolution found in master playlist file\n",
    "            if biggest_res[0] >= width:\n",
    "                continue\n",
    "\n",
    "            biggest_res = (width, height)\n",
    "            best_url = match.group(3)\n",
    "\n",
    "        # recurse (max 1 iteration expected)\n",
    "        return (biggest_res[0], biggest_res[1], best_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def save_m3u8(url: str, folder_path: str, video_name: str):\n",
    "    file_path = Path(os.path.join(dist_root, folder_path, f\"{video_name}.m3u8\"))\n",
    "\n",
    "    if file_path.is_file():\n",
    "        os.remove(file_path)\n",
    "\n",
    "    with urllib.request.urlopen(url) as html:\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            html = html.read().decode(\"utf-8\")\n",
    "            f.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file, parse data, find files and download m3us (sequential)\n",
    "def pilfer_and_download(\n",
    "    folder_sites: List[str],\n",
    "    folder_path: str = \"\",\n",
    "):\n",
    "    print(\n",
    "        f\"----------------------- Process path {folder_path} start: {round(time.time() - start_time, 3)} seconds\"\n",
    "    )\n",
    "\n",
    "    create_directory(os.path.join(dist_root, folder_path))\n",
    "\n",
    "    print(f\"--- Directory created {round(time.time() - start_time, 3)} seconds\")\n",
    "\n",
    "    for index, site in enumerate(folder_sites):\n",
    "        video_name, url = parse_site_string(\n",
    "            site\n",
    "        )  # Parse name of video and playlist url from file line\n",
    "\n",
    "        if url.strip() != \"_\":\n",
    "            print(\n",
    "                f\"--------- Process site {video_name}:  {round(time.time() - start_time, 3)} seconds\"\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                f\"--------- Ignoring file {video_name} with ignore tag. Counting as index.\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        highest_res_file = get_media_playlist_file_path(\n",
    "            video_name, url\n",
    "        )  # Read file URL and get the biggest-resolution media file\n",
    "\n",
    "        print(f\"--- Found biggest file: {round(time.time() - start_time, 3)} seconds\")\n",
    "\n",
    "        full_file_name = f\"{index}_{video_name}_{highest_res_file[0]}x{highest_res_file[1]}\"  # Create name from data\n",
    "\n",
    "        save_m3u8(\n",
    "            highest_res_file[2], folder_path, full_file_name\n",
    "        )  # Download and save m3u8 file to path\n",
    "\n",
    "        print(f\"--- Saved file: {round(time.time() - start_time, 3)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run ripper\n",
    "siteLib: Dict[str, List[str]] = read_links_from_file(source_file)\n",
    "\n",
    "print(f\"--- Links read {round(time.time() - start_time, 3)} seconds\")\n",
    "\n",
    "iterate_on_lib(siteLib, pilfer_and_download)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
